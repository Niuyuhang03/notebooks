# 毕设

## 背景

### Embeddings分类

+ 将实体和关系转化为连续的向量空间，并保留原式知识图谱结构。
  + 张量分解模型
    + RESCAL
    + DistMult
    + HOLE
    + ComplEx
  + 距离模型
    + SE
  + 翻译模型
    + TransE模型通过训练，尽可能使得嵌入得到的向量满足：头实体向量+关系向量$\approx$尾实体向量。但TransE模型的问题在于，如果h和$t_1$、h和$t_2$都有关系l，即都满足$h+l\approx t_1,h+l\approx t_2$，得到$t_1\approx t_2$，但这两个尾实体并不相同，不应该用一个向量表示，即在一对多，多对一，多对多的问题上，TransE模型存在一定的问题。
    + TransH、TransR、TranSparse
  + 图卷积模型
    + GCN和R-GCN
    + GAT
    + ConvE
    + ConvKB

### Attention Mechanisms

#### 序列模型中

+ 序列模型：常见序列模型如seq2seq可以应用于机器翻译、图片描述生成、语音识别等问题，通常框架为Encoder-Decoder。Encoder每次接受一个单词 $x_i$ ，接收完一个句子的所有单词后，输出一个固定长度的语义编码向量$c=f(x_1,x_2,...)$。Decoder每次会根据c和先前输出结果输出一个单词$y_i=g(c,y_1,y_2,...,y_{i-1})$，此后用相应搜索算法和打分找到输出单词的最佳顺序。

  ![序列模型](https://img-blog.csdn.net/20171122145456283)

+ 序列模型中的注意力机制：注意力机制在序列模型中已经普遍使用。在机器翻译问题中，Decoder的每一个输出单词都会以相同方式用到Encoder的语义编码$c$。带有注意力机制的序列模型中，将Encoder在不同时间步得到多个语义编码$c_i$，不同语义编码$c_i$生成时，对输入单词的注意力程度不同。Decoder翻译时每个词用到不同的序列，即不同的输出词之间的放在输入词上的注意力不同，$y_i=g(c_i,y_1,y_2,...,y_{i-1})$。

  ![序列模型中的注意力机制](https://img-blog.csdn.net/20171122151317417)

#### 图模型中

+ 图网络：更不规则、更一般化的数据可以用图结构来表示，知识图谱通常以G=(E,R,S)三元组来表示，E为实体集合，R为关系集合，S为E×R×E的三元组集合。因此兴起了GCN（Graph Convolution Networks），但由于GCN采用的是谱方法，模型依赖图结构，另一张图的节点邻居数发生变化后会导致之前的模型不可用。MoNet（mixture model CNN）则是非谱方法，节点的邻居数可变。

+ 图注意力网络：GAT（Graph Attention Networks）利用了MoNet的非谱方法。在GCN中，节点i的周围节点对其的作用是相等的，GAT在此基础上加上了图的注意力机制，利用self-attention机制在自身上计算attention，根据对邻居节点的注意力系数不同，关注作用比较大的节点。在GAT模型中，对于N个$1*F$维节点$h_1,h_2,...,h_N$，先通过和$F'*F$维的共享的权重矩阵W相乘作线性变换，得到有更高表达能力的$1*F'$维特征$Wh_i$。对于每个节点i和所有与它直接相连的节点j，根据公式a计算出注意力系数（标量）$e_{ij}=a(Wh_i,Wh_j)=a^T[Wh_i||Wh_j]$，通过softmax（归一化）和激活得到注意力权重（标量）$\alpha_{ij}=\frac{exp(LeakyReLU(e_{ij})}{\Sigma_{k\in N_i}exp(LeakyReLU(e_{i,k}))}$。最后根据注意力权重不同，不同程度结合周围节点的特征，得到N个$1*F'$维的输出向量$h_1,h_2,...,h_N$，其中$h_i'=\sigma(\Sigma_{j\in N_i}\alpha_{ij}Wh_j)$。

  ![GAT](https://i.loli.net/2020/01/05/GQmYyRXH4jBpLE5.png)

  GAT还采用了多头注意力，多头注意力可以稳定图注意力效果，丰富模型，每个头相当于从一个角度分析j对i的重要性，类比cv中的channel。每个头有独立的参数，在GAT整合得到h‘向量时，通常中间层采用拼接$h_i'=||_{k=1}^K\sigma(\Sigma_{j\in N_i}\alpha_{ij}^kW^kh_j)$，最后一层采用平均$h_i'=\sigma(\frac{1}{K}\Sigma_{k=1}^K\Sigma_{j\in N_i}\alpha_{ij}^kW^kh_j)$。

### 最新成果

+ ADSF-RWR（Adaptive Structural Fingerprints for Graph Attention Networks-Random Walk with Restart）在GAT基础上，==利用图的结构信息==，将注意分给节点周围k跳视野内的部分节点。此时节点之间的相似性除了GAT中的特征相似性，还有结构相似性。定义节点i和周围节点组成子图的结构特征为指纹$F_i$，得到特征相似性$e_{ij}=A_{fea}(Wh_i,Wh_j)=a^T[Wh_i||Wh_j]$，结构相互作用$s_{ij}=A_{str}(F_i,F_j)=\frac{\Sigma_{p\in(V_i\cup V_j)\min(w_{ip},w_{jp})}}{\Sigma_{p\in(V_i\cup V_j)\max(w_{ip},w_{jp})}}$，w为中心节点和指纹内其他节点的相似性。二者经过softmax和LeakyReLU激活后得到$\overline e_{ij}$和$\overline s_{ij}$，整合得到最终的注意力权重$a_{ij}=\frac{\alpha(\overline e_{ij})\overline e_{ij}+\beta(\overline s_{ij})\overline s_{ij}}{\alpha(\overline e_{ij})+\beta(\overline s_{ij})}$，其中$\alpha$和$\beta$为激活函数。最后得到输出向量$h_i'=\sigma(\Sigma_{j\in N_i}\alpha_{ij}Wh_j)$。

  ![ADSF-RWR](https://i.loli.net/2020/01/06/HjnLxlhZ8Y4yN9z.png)

+ Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs论文在GAT基础上利用了关系。求新的h'向量时，首先对三元组$(e_i,e_j,r_k)$进行==拼接==和线性变换==$c_{ijk}=W_1[h_i||h_j||g_k]$==，激活$b_{ijk}=LeakyReLU(W_2c_{ijk})$，softmax得到注意力权重$a_{ijk}$，最后得到$h_i'=\sigma(\Sigma_{j\in N_i}\Sigma_{k\in R_{ij}}\alpha_{ijk}c_{ijk})$。和GAT一样采用多头注意力，中间层拼接，最后一层平均。同样加上self-attention，得到$h_i''=Wh_i+h_i'$。对于关系，只做了一个线性变换$g_k'=g_kW$。使用ConvKB作为打分。

  ![image.png](https://i.loli.net/2020/01/08/qXCDAQpivJs9V7m.png)

+ KANE（Knowledge Graph Attention Networks for Enhancing Knowledge Graph Embedding）中，==将三元组根据关系不同，进一步分为（实体-关系-实体）三元组$T_R$和（实体-关系-属性）三元组$T_A$==，其中（实体-关系-属性）三元组由于有更多的信息。先用LSTM对两种三元组分别进行embeddings。以第一种三元组为例，注意力权重为$\pi(h,r,t/a)=LeakyRelu((Wr)^TW(r+t))$并进行softmax，输出$h_i'=\Sigma_{t\in N_h}\pi(h,r,t)W(r+t)$，多头注意力同样中间层拼接最后一层平均。

  ![KANE](https://i.loli.net/2020/01/06/rLEBTFoZ4qcxUgs.png)

+ TransAt（Translation with Attention）先采用K-means==检查头尾实体类和关系是否有连接构成三元组的可能==。对于不可能的组合，距离设为无穷。对于可能的组合，再计算$f_r(h,t)=P_r(h)+r-P_r(t)$，其中P为==将向量投影为和关系r有关的向量==操作，通过同一类实体计算PCA并设置阈值得到。应对ORC（one-relation-circle）结构，设置同一实体在头和在尾时的向量不同，公式变为$f_r(h,t)=P_r(\sigma(r_h)h)+r-P_r(\sigma(r_t)t)$

+ A2N

## 开题报告

### 研究目的和意义

​		随着移动互联设备的普及和移动通信技术的进步，越来越多的用户开始了解和使用搜索引擎解决问题。传统搜索引擎将包含被搜索关键词的全部网页作为搜索结果，在经过一定的排序后呈现给用户，再由用户筛选有效信息。这样的搜索模式在解决 “梅西的故事”这样具有模糊答案的问题时表现尚可，用户在前几页即可找到相应的答案。然而，近年来的信息爆炸使得搜索结果的数量不断增加，排序算法越来越难以在前几条结果中给出得到用户认可的答案，在回答“梅西的国籍是什么”这样具有唯一准确答案的问题时，搜索引擎仍需要用户点开结果网页筛选信息，就显得过于繁琐。

​		为了解决这一问题，Google提出了知识图谱，将知识通过图结构的形式表现出来，在呈现搜索结果时，直观地显示被搜索关键词的相关信息。使用知识图谱进行研究的首要工作，就是将知识从图结构编码到低维向量空间，即知识表示学习的过程。近年来，受到人在观察时对不同事物的注意力不同的启发，出现了基于注意力机制的知识表示学习，这种模型称为图注意力网络，可以应用于搜索、推荐、自动问答等众多领域，在知识图谱的实体分类、关系预测等任务上获得了更好的表现。

### 国内外研究现状

​		知识表示学习地主要方法有张量分解模型、距离模型、翻译模型和图卷积模型。定义知识图谱中第k个<头实体，关系，尾实体>的三元组向量表示为                                。

#### 张量分解模型

​		RESCAL[[1](#_ENREF_1)]双线性模型是一种张量分解模型，通过将整个知识图谱表示为一个张量  ，根据  分解张量，得到所有实体特征组成的矩阵  和可以表示实体之间关系的核心矩阵  ，其中R的每个二维张量  都是一种具体关系的参数。在关系预测任务中，定义  为两个实体对于是否具有该具体关系的评分，评分越高，三元组越有可能成立。

​		由于RESCAL模型的核心矩阵  的参数过多，一些模型尝试对RESCAL模型进行优化。DistMult[[2](#_ENREF_2)]模型将整个张量  表示为对角矩阵，即将关系变为对称关系，这种方法在很多数据集上并不够合理。HolE[[3](#_ENREF_3)]模型则通过循环相关的操作，减少参数的同时，允许对称关系。ComplEx[[4](#_ENREF_4)]模型在DistMult基础上，将向量空间从实空间扩展到了复数空间，而三元组的评分函数则是张量相乘后的实数部分。

#### 距离模型

​		SE[[5](#_ENREF_5)]距离模型通过对每一组d维头实体向量和尾实体向量，分别构造一个$d*d$维的矩阵$W_k^h$和$W_k^t$，定义投影的向量差$||W_k^he_h-W_k^te_t||_1$为投影后的距离，距离采用L1范数。投影后的距离越小，头实体和尾实体之间越有可能存在该关系。但使用两个投影向量来定义一种关系的方式，无法直观表示出相似关系的在矩阵上的相似性。如实体“国王”和“王后”的关系，应当和实体“丈夫”和“妻子”之间的关系具有一定的联系，这是距离模型无法表示的。

#### 翻译模型

​		在张量分解模型和距离模型中，关系往往用矩阵点乘来表示。受到word2vec[[6](#_ENREF_6)]的词向量平移不变的启发，提出了翻译模型TransE[[7](#_ENREF_7)]。TransE模型将关系表示为向量$r_k$，翻译的过程可以表示为$e_t\approx e_h+r_k$，即将头实体按照关系平移得到尾实体。通过平移，可以很好的表示出相似关系的向量也相似。但TransE模型很难在1-n问题有较好的表现，如问题“苹果公司的创始人有谁”中，头实体和关系向量都相同，会翻译为相同的尾实体，这显然与现实不符。同理，在n-1和n-n问题上，TransE模型也有缺陷。

​		TransH[[8](#_ENREF_8)]模型的提出就是为了解决这个问题。不同于TransE模型的简单平移，TransH模型中采用了向量投影的方法。TransH模型认为，不同三元组中的实体，其向量不会完全相同。对于每个三元组，定义投影矩阵$W_r$，将头实体向量和尾实体向量投影到投影平面，投影公式为$e_\bot=e-W_r^TeW_r$，翻译的过程随即变为$e_{t\bot}\approx e_{h\bot}+r_k$。投影操作使得实体在不同三元组中，可以使用其一个分量，一定程度上解决了TransE模型的问题。

#### 图卷积模型

​		为了获得更有表现力的实体和关系向量，GCN[[9](#_ENREF_9)]等图卷积模型将实体周围的节点特征按照一定权重融合到该节点上。GCN模型中每个节点对中心节点的重要性相同，不同关系之间权值共享，在很多实体上并不合理。

​		受到人在解决不同问题时，对不同物体的注意力不同的启发，提出了利用注意力机制的图注意力网络GAT[[10](#_ENREF_10)]。GAT模型在GCN模型的基础上，对周围不同的节点采用不同注意力权重，将注意力放在作用比较大的节点上，融合周围节点的特征。GAT模型采用了Mask Attention机制，即只关注邻居节点的特征，并使用多头注意力，每个头相当于从一个角度分析注意力，使得注意力更丰富和稳定。但GAT模型忽略了关系对注意力机制的影响。

​		ADSF模型在GAT模型的基础上，利用图的结构信息，将注意力分给节点周围k跳视野内的部分节点。此时节点之间的相似性除了GAT模型中的特征性相似性，还有结构相似性。将二者的注意力权重整合为最终的注意力权重，得到表示好的实体和关系向量。此外，还有关系预测任务常用的评分模型ConvE[[11](#_ENREF_11)]，将头实体和关系向量合并为矩阵，通过卷积操作向量化，与尾实体相乘，得到对三元组关系预测的评分。

​		也有模型[[12](#_ENREF_12)]认识到了关系在知识图谱中的重要性，在GAT模型的基础上，提出了新的知识表示学习方法。该模型通过将三元组的三个向量简单拼接，再计算注意力权重，并将计算范围扩大到了周围n跳。

### 研究内容

​		在知识图谱中，实体和关系同样重要。针对图注意力网络的缺点，本文在实体注意力的基础上，增加了关系注意力权重。此外，受到ADSF模型的启发，进一步在注意力中考虑图的结构信息中隐含的结构相似性，并加入到注意力权重中。对改进的图注意力网络表示出的实体和关系向量，进行实体分类和关系预测。

### 研究方案和技术路线

#### 数据集标注和预训练

​		模型使用FB15k-237[[13](#_ENREF_13)]数据集和WN18RR[[14](#_ENREF_14)]数据集，对数据集中的实体标注标签，每个实体不限于一个标签。FB15k-237数据集的实体包括电影、学校、人物等类别，WN18RR数据集包括名词、动词、形容词等类别。在TransE模型上进行预训练，得到表示好的实体和关系向量。

#### 图注意力网络改进和扩展

​		在图注意力网络中实体注意力的基础上，考虑利用知识图谱的关系和结构信息。在实体注意力的基础上，增加关系注意力，用关系信息构造注意力权重。在结构上，将注意力的范围从Mask Attention的邻居节点扩展到周围k跳，计算其结构相互作用，并作为注意力权重的一部分，尽可能多的考虑具有一定结构相似性的实体，得到更有表现力的实体和关系向量。

#### 实体分类和关系预测任务

​		在实体分类任务上，使用改进的图注意力网络对表示好的向量进行测试集实体的标签预测。将R-GCN[[15](#_ENREF_15)]、RDF2VEC[[16](#_ENREF_16)]等模型作为基准模型，在标注好的FB15k-237数据集和WN18RR数据集上验证模型表现。

​		在关系预测任务上，使用改进的图注意力网络作为编码器，采用ConvE、DistMult和ComplEx三种模型作为解码器，对改进的图注意力网络表示好的<头实体-关系-尾实体>向量三元组作为解码里器的初始化向量，进行关系预测。

### 研究技术难点

+ 数据集标注需要合适的算法，难以衡量标注结果合理性。

+ 图注意力网络表示出的结果向量可解释性较差，调优困难。

+ 模型参数量多，计算规模大，需要优化。

### 预期结果

​	在实体分类和关系预测任务上，改进的图注意力网络达到较基准模型更优水平。

### 进度安排

第1-3周，阅读相关资料，调研国内外研究成果，完成开题报告和开题答辩。

第4-6周，实现数据集实体标注，完成图注意力网络原始模型搭建。

第7-9周，改进图注意力网络原始模型，完成基准模型搭建，在标注好的数据集上进行实验，根据结果评估问题，完成中期答辩。

第10-13周，搭建关系预测评估模型，根据实验结果改进模型性能。

第14-16周，完成毕业论文撰写，进行终期答辩。

## 开题ppt纲要

各位老师好，我的毕设题目是。。。

我的报告主要分为五个方面

==click==

首先是研究的背景和意义。知识图谱可以用来解决搜索引擎中，通过query box直接返回问题结果的技术。

==next==

知识图谱的结构是一张有向图，包括实体和实体之间的关系。想要研究和利用知识图谱，就需要将实体和关系变成向量或矩阵的形式

这个表示的过程，就是知识表示学习，就是这篇论文所研究的对象

==next==

目前的知识表示学习学习主要有四种方法，分别是

==next==

目前最新的GAT模型可以实现将实体和关系表示成向量，他是基于注意力机制实现的，但GAT模型存在很多问题。我们提出了一个，结合关系注意力和图的结构信息的关系网络R-GAT。

相比于原先的GAT网络，这个网络的改进之处有：

预训练

加入关系注意力权重和结构信息

应用上增加了实体分类和关系预测

==next==

红色部分是目前我已经完成的工作，分别是。。。

==next==

实体标注中，

==next==







上次的问题：

引入噪声：3跳内本来就是有一些联系的，高斯衰减，越外层的权重越低

数据集：fb和wn数据量较好

标注算法：wordnet，根据描述

标注效果差，更换数据集？虽然实体分类是知识图谱的一个任务之一，但是很少有人对知识图谱进行embeddings操作之后应用到实体分类里。知识图谱的实体分类可以用半监督的方法解决金融、生物领域图谱的实体标注问题，这些领域特征清晰，样本少

## 相关论文

+ [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)：seq2seq，序列模型。
+ [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)：序列模型中的注意力机制。
+ [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907)：GCN，谱方法。
+ [Modeling Relational Data with Graph Convolutional Networks](https://arxiv.org/abs/1703.06103)：R-GCN，使用关系数据。
+ [Geometric deep learning on graphs and manifolds using mixture model CNNs](https://arxiv.org/abs/1611.08402)：MoNet，非谱方法
+ [Attention Is All You Need](https://arxiv.org/abs/1706.03762)：多头注意力。
+ [Graph Attention Networks](https://arxiv.org/abs/1710.10903)：GAT，图注意力网络，多头，只对直接相连邻居有注意力。
+ [Relational Graph Attention Networks](https://arxiv.org/abs/1904.05811)：RGAT，关系图注意力网络。
+ [Translating Embeddings for Modeling Multi-relational Data](https://papers.nips.cc/paper/5071-translating-embeddings-for-modeling-multi-relational-data.p)：TransE，图嵌入模型。
+ [Adaptive Structural Fingerprints for Graph Attention Networks](https://openreview.net/forum?id=BJxWx0NYPr)，[代码](https://github.com/AvigdorZ/ADaptive-Structural-Fingerprint)：ADSF-RWR，在GAT基础上利用了结构信息，即可以注意到周围超过1跳的节点。
+ [Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs](https://arxiv.org/abs/1906.01195)，[代码](https://github.com/deepakn97/relationPrediction)：在GAT基础上利用了关系，即在求h'时拼接了关系，在求g'时做了线性变换。用ConvKB作为打分。
+ [Learning High-order Structural and Attribute information by Knowledge Graph Attention Networks for Enhancing Knowledge Graph Embedding](https://arxiv.org/abs/1910.03891v2)：KANE，将关系分为关系和属性两种。
+ [Translating Embeddings for Knowledge Graph Completion with Relation Attention Mechanismfor Knowledge Graph Completion with Relation Attention Mechanism](https://www.ijcai.org/proceedings/2018/596)：TransAt，先检查三元组可行性，只计算可行的组合。向量投影为和关系r有关的向量。
+ [Knowledge Graph Embedding with Multiple Relation Projections](https://arxiv.org/abs/1801.08641)：应对ORC结构，设置同一实体在头和尾的向量不同。

+ [A2N: Attending to Neighbors for Knowledge Graph Inference](https://www.aclweb.org/anthology/P19-1431/)：A2N

+ [Convolutional 2D Knowledge Graph Embeddings](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17366/15884https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17366/15884)：ConvE
+ [Embedding Entities and Relations for Learning and Inference in Knowledge Bases](https://arxiv.org/abs/1412.6575)

+ [Complex Embeddings for Simple Link Prediction](http://proceedings.mlr.press/v48/trouillon16.pdf)

## 相关问题

+ 知识图谱的表示学习Knowledge Graph Embedding和网络图的表示学习Knowledge Graph Embedding有什么区别？
  + 在知识图谱的表示学习中，关系和实体同样重要，关系有很多种，这也就是为什么知识图谱中常常强调<头实体-关系-尾实体>三元组。知识表示学习中，需要研究的是如何用向量刻画实体和关系。
  + 在网络图表示学习中，研究的是节点的网络结构信息，但并不了解具体关系和关系之间有什么区别。



4.20：ADSF修改bug，缺少的adj文件用graph文件代替了。列出各个文件格式，准备替换为wn和fb数据。

4.21：更新fb数据，未分类数据给了film类别。复制到各个项目中，==rgcn运行数据失败，暂未处理==。服务器在运行adsf，gpu==占用但占用率为0==

4.22：运行rwr，==10min一个epoch==，71.2%左右。

4.23：实现adsf上读取fb和wn，==A*算法更慢==，citeseer共3000个实体，fb15000个，wn40000个。

4.24：运行adsf，1个epoch1s，71.2%左右。==adsf和rwr和论文相反==

4.25：rwr在fb和wn上==十二个小时也没跑完预处理，A*慢==。升级torch满足nonzero，优化pygat的loss和acc。==gpu占用率低==



cpu跑rwrwn预处理：3037070，rwrfb预处理：3036622

gpu跑rwrf_b4000和rwr_wn4000



fb3跳基本已经7000+实体

wn4跳才有部分满足4000实体